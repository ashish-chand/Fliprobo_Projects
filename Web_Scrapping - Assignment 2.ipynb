{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "\n",
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Analyst')\n",
    "#finding element for job location bar\n",
    "\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys('Bangalore')\n",
    "\n",
    "#do click using class_name function\n",
    "\n",
    "search_btn = driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract data having the job title \n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles=[]\n",
    "for i in titles_tags:\n",
    "    job_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract all the data having the job location\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "job_loc=[]\n",
    "for i in location_tags:\n",
    "    job_loc.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract all the data having the names\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_name=[]\n",
    "for i in companies_tags:\n",
    "    company_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# so lets extract the experience required data\n",
    "experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "experience_req=[]\n",
    "for i in experience_tags:\n",
    "    experience_req.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(experience_req),len(company_name),len(experience_req),len(job_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles[:10]\n",
    "jobs['Company']=company_name[:10]\n",
    "jobs['Experience_required']=experience_req[:10]\n",
    "jobs['Location']=job_loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience_required</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product Data Analyst ( Leading MNC )</td>\n",
       "      <td>BRAINHUNT CONSULTANTS PRIVATE LIMITED</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Quant &amp; Data Mining</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst (Contractual)</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst (Contractual)</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marketing Technology Data Analyst</td>\n",
       "      <td>WeGo</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Process Data Analyst</td>\n",
       "      <td>Hitachi ABB Power Grids</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - Category Demand Management (Rev...</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst - Revenue &amp; Growth</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Technical Data Analyst - Progton Technologies</td>\n",
       "      <td>Progton Technologies LLP</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Near Pte. Ltd.</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0               Product Data Analyst ( Leading MNC )   \n",
       "1                 Data Analyst - Quant & Data Mining   \n",
       "2                         Data Analyst (Contractual)   \n",
       "3                         Data Analyst (Contractual)   \n",
       "4                  Marketing Technology Data Analyst   \n",
       "5                               Process Data Analyst   \n",
       "6  Data Analyst - Category Demand Management (Rev...   \n",
       "7                    Data Analyst - Revenue & Growth   \n",
       "8      Technical Data Analyst - Progton Technologies   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                 Company Experience_required  \\\n",
       "0  BRAINHUNT CONSULTANTS PRIVATE LIMITED             2-5 Yrs   \n",
       "1                               Catalyst             2-6 Yrs   \n",
       "2      Flipkart Internet Private Limited             1-4 Yrs   \n",
       "3      Flipkart Internet Private Limited             1-4 Yrs   \n",
       "4                                   WeGo             2-4 Yrs   \n",
       "5                Hitachi ABB Power Grids             2-6 Yrs   \n",
       "6               Myntra Designs Pvt. Ltd.             1-4 Yrs   \n",
       "7               Myntra Designs Pvt. Ltd.             2-3 Yrs   \n",
       "8               Progton Technologies LLP             0-2 Yrs   \n",
       "9                         Near Pte. Ltd.             2-5 Yrs   \n",
       "\n",
       "                         Location  \n",
       "0             Bangalore/Bengaluru  \n",
       "1             Bangalore/Bengaluru  \n",
       "2  Bangalore/Bengaluru(Bellandur)  \n",
       "3  Bangalore/Bengaluru(Bellandur)  \n",
       "4             Bangalore/Bengaluru  \n",
       "5             Bangalore/Bengaluru  \n",
       "6             Bangalore/Bengaluru  \n",
       "7             Bangalore/Bengaluru  \n",
       "8             Bangalore/Bengaluru  \n",
       "9             Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "\n",
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "#finding element for job location bar\n",
    "\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys('Bangalore')\n",
    "\n",
    "#do click using class_name function\n",
    "\n",
    "search_btn = driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of jobs detail have 10 rows and 4 columns \n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bion</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Python/ SQL</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Python/r</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - KPO</td>\n",
       "      <td>Antrors HR Solutions</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Talent Corner HR Services Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data scientist - Bangalore - only IITand IIM</td>\n",
       "      <td>Industrial Personnel Network</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>COUTURE AI PRIVATE LIMITED</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0                                Data Scientist   \n",
       "1                  Data Scientist - Python/ SQL   \n",
       "2                                Data Scientist   \n",
       "3             Data Scientist - Machine Learning   \n",
       "4                     Data Scientist - Python/r   \n",
       "5                          Data Scientist - KPO   \n",
       "6             Data Scientist - Machine Learning   \n",
       "7                                Data Scientist   \n",
       "8  Data scientist - Bangalore - only IITand IIM   \n",
       "9                                Data Scientist   \n",
       "\n",
       "                            Company  Experience            Locations  \n",
       "0                               Bion    2-7 Yrs  Bangalore/Bengaluru  \n",
       "1                           Catalyst    2-7 Yrs  Bangalore/Bengaluru  \n",
       "2                           Catalyst    2-7 Yrs  Bangalore/Bengaluru  \n",
       "3                           Catalyst    2-7 Yrs  Bangalore/Bengaluru  \n",
       "4                           Catalyst    2-6 Yrs  Bangalore/Bengaluru  \n",
       "5               Antrors HR Solutions    2-5 Yrs  Bangalore/Bengaluru  \n",
       "6                        AugmatrixGo    2-5 Yrs  Bangalore/Bengaluru  \n",
       "7  Talent Corner HR Services Pvt Ltd    2-5 Yrs  Bangalore/Bengaluru  \n",
       "8       Industrial Personnel Network    1-6 Yrs  Bangalore/Bengaluru  \n",
       "9         COUTURE AI PRIVATE LIMITED    2-5 Yrs  Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so lets extract all the data having the job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles=[]\n",
    "for i in titles_tags:\n",
    "    job_titles.append(i.text)\n",
    "            \n",
    "#so lets extract all the data having the job location\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "job_loc=[]\n",
    "for i in location_tags:\n",
    "    job_loc.append(i.text)\n",
    "            \n",
    "#so lets extract all the data having the names\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_name=[]\n",
    "for i in companies_tags:\n",
    "    company_name.append(i.text)\n",
    "        \n",
    "# so lets extract the experience required data\n",
    "experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "experience_req=[]\n",
    "for i in experience_tags:\n",
    "    experience_req.append(i.text)\n",
    "            \n",
    "            \n",
    "    \n",
    "Jobs=pd.DataFrame({})\n",
    "Jobs['Title']=job_titles[:10]\n",
    "Jobs['Company ']=company_name[:10]\n",
    "Jobs['Experience']=experience_req[:10]\n",
    "Jobs['Locations']=job_loc[:10]\n",
    "    \n",
    "print(\"Shape of jobs detail have {} rows and {} columns \\n.\".format(*Jobs.shape))\n",
    "Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Q2- ii - 2 Now make a  full job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "job_titles=[]\n",
    "job_description=[]\n",
    "\n",
    "for i in urls[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    #fetching the job title\n",
    "    try:\n",
    "        job=driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "        job_titles.append(job.text)\n",
    "    except:\n",
    "         job_titles.append('--')\n",
    "    \n",
    "    try:\n",
    "        job_desc=driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        job_description.append(job_desc.text)\n",
    "    except:\n",
    "         job_description.append('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Scientist - Python/ SQL',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist - Python/r',\n",
       " 'Data Scientist - KPO',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist',\n",
       " 'Data scientist - Bangalore - only IITand IIM',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Job description\\nResponsibilities\\n\\nCollaborate with product and business teams to understand all aspects of the problem\\n\\nDefine the right target metrics that best represent the end-user value\\n\\nApply knowledge of ML, statistics, and advanced mathematics to conceptualize, experiment and design an intelligent system\\n\\nWork with engineers to build the system end-to-end including Big Data pipelines and ensure the serving system is scalable and highly performant.\\n\\nQualifications\\n\\nA Bachelor's degree or a higher degree in Computer Science, Statistics, Mathematics or a related field.\\n\\nStrong problem-solving and programming skills with a deep understanding of data structures and algorithms.\\n\\nSolid understanding of mathematical underpinnings behind Machine Learning algorithms and proficiency in probability, statistics, linear algebra, calculus, and optimization.\\n\\nMust have 2+ years of experience in ML with a proven record of successful ML projects with strong individual contribution\\n\\nExperience with NLP, Distributed Systems, large scale computing, Big Data technologies like Hadoop and Spark are plus.\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :MCA in Computers\\nDoctorate :Doctorate Not Required\\nKey Skills\\nData ScienceNLPData ScientistMachine learningPredictiveTime SeriesRegressionPredictivityAnalyticsPython\",\n",
       " \"Job description\\nRoles and responsibilities \\nJob description\\n\\nSkill: SQL, Python, Business Analysis, Data Science;\\n\\nExp: 2-7 years;\\n\\nJob Description Ensuring quality in crowd sourcing model is the biggest challenge to solve for. Being the first data scientist of the company, you shall be responsible for building robust algorithms ensure quality, from scratch.Responsibilities- Develop models to derive maximum quality from crowd sourced data\\n\\nDerive insights and identify opportunities through the use of algorithmic, statistical, mining & visualisation techniques- Work closely with engineering to implement aforementioned models\\nRequired Candidate profile\\nRequirements\\n\\nBachelors or above in Mathematics, Statistics, CS or related fields.\\n\\nMin. 2 years experience with mathematical modelling, statistical analysis, machine learning, NLP- Must have implemented machine learning based solution which is being used in production\\n\\nProgramming proficiency, preferably with Python, R, SQL, Java and equivalents- Experience of working with relational and non-relational databasesWe're a fast growing startup, looking for talented and ambitious individuals who want to join us on this journey and build awesome things which can change the way work gets done. You shall get,- Complete Ownership, Flexible timings\\n\\nWe deal with millions of data points every day and we can assure you that you will have no dearth of data to work with in this job- Pay as per industry standards. Lucrative stock options.\\n\\nAn awesome office to work in and awesome people to work with- Weekend beer! Munchies on the house )\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Tech/B.E. in Computers, B.A in Statistics, Maths, B.Sc in Maths, Statistics\\nPG :Any Postgraduate in Any Specialization\\nDoctorate :Any Doctorate in Any Specialization, Doctorate Not Required\\nKey Skills\\nData ScienceJavaRNLPAlgorithmsData ScientistMachine LearningStatistical AnalysisStatisticsPythonSQL\",\n",
       " \"Job description\\nResponsibilities\\n\\nCollaborate with product and business teams to understand all aspects of the problem\\n\\nDefine the right target metrics that best represent the end-user value\\n\\nApply knowledge of ML, statistics, and advanced mathematics to conceptualize, experiment and design an intelligent system\\n\\nWork with engineers to build the system end-to-end including Big Data pipelines and ensure the serving system is scalable and highly performant.\\nRequired Candidate profile\\nQualifications\\n\\nA Bachelor's degree or a higher degree in Computer Science, Statistics, Mathematics or a related field.\\n\\nStrong problem-solving and programming skills with a deep understanding of data structures and algorithms.\\n\\nSolid understanding of mathematical underpinnings behind Machine Learning algorithms and proficiency in probability, statistics, linear algebra, calculus, and optimization.\\n\\nMust have 2+ years of experience in ML with a proven record of successful ML projects with strong individual contribution\\n\\nExperience with NLP, Distributed Systems, large scale computing, Big Data technologies like Hadoop and Spark are plus.\\nRoleOther\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryOther\\nEducation\\nUG :B.Tech/B.E. in Computers, B.Sc in Maths, Computers, Statistics\\nPG :MCA in Computers\\nDoctorate :Doctorate Not Required\\nKey Skills\\nData ScienceNLPData ScientistMachine learningPredictiveTime SeriesRegressionPredictivityAnalyticsPython\",\n",
       " 'Job description\\nRoles and Responsibilities\\n- Implement data-driven solutions based on advanced ML and optimization algorithms to address business problems\\n\\n- Research, experiment, and innovate MLstatistical approaches in various application areas of interest and contribute to IP\\n\\n- Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (trainingevaluationmonitoring)\\n\\n- Deploy, maintain, and debug MLdecision models in a production environment\\n\\n- Analyze and assess data to ensure high data quality and correctness of downstream processes\\n\\n- Communicate results to stakeholders and present datainsights to participate in and drive decision making\\nRoleData Analyst\\nIndustry TypeBanking\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :BCA in Computers, B.Tech/B.E. in Any Specialization, B.Sc in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nDoctorate :Doctorate Not Required\\nKey Skills\\nData ScienceData QualityData ScientistStatistical ModelingStatistical AnalystMachine Learning',\n",
       " \"Job description\\nWhat You'll Do :\\n\\n- Leverage data to perform intensive analysis across all areas of our business to catalyze product development\\n\\n- Design experiments and interpret the results to draw detailed and actionable conclusions\\n\\n- Generate and execute on ideas for exploratory analysis to shape future projects and provide recommendations for actions\\n\\n- Perform time-series analyses, hypothesis testing, and causal analyses to statistically assess relative impact and extract trends\\n\\n- Create models to enhance understanding of user behavior and predict future performance of cohorts\\n\\n- Create dashboards and reports to regularly communicate results and monitor key metrics\\n\\n- Present findings to senior management to guide business decisions\\n\\n- Collaborate with cross-functional teams across disciplines such as product, engineering, operations, and marketing\\n\\nRequired Candidate profile\\nWhat You'll Need :\\n\\n- 3-5 years of experience in a quantitative analysis role\\n\\n- BE/BS/MS in Physics, Economics, Applied Math, Statistics, Engineering, Computer Science, or other quantitative field (advanced degrees are a plus)\\n\\n- Comfortable writing code and contributing to a code base in Python or R\\n\\n- Proficient in writing and understanding complex SQL; experience working with large data sets\\n\\n- Advanced knowledge of experimentation and statistical methods\\n\\n- Ability to deliver on tight timelines and move quickly while maintaining attention to detail\\n\\n- Collaborate closely with cross-functional teams to execute on decisions\\n\\n- Self-driven and proactive with the ability to work in a self-guided manner\\n\\n- Excellent communication and organization skills\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Tech/B.E. in Computers, B.Sc in Other Specialization, Physics, Statistics\\nPG :MS/M.Sc(Science) in Physics, Computers, Statistics\\nDoctorate :Doctorate Not Required\\nKey Skills\\nData ScienceRData ScientistData Managementproduct developmentPythonSQL\",\n",
       " 'Job description\\nResponsibilities:\\n\\n- Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\\n\\n- Mine and analyze data from company databases to drive optimization and improvement\\n\\n- Assess the effectiveness and accuracy of new data sources and data gathering techniques.\\n\\n- Develop custom data models and algorithms to apply to data sets.\\n\\n- Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.\\n\\n- Develop company A/B testing framework and test model quality.\\n\\n- Coordinate with different functional teams to implement models and monitor outcomes.\\n\\n- Develop processes and tools to monitor and analyze model performance and data accuracy\\n\\nRequired Candidate profile\\nQualifications & Experience:\\n\\n- PG / MBA with 2 to 5 Yrs Experience with strong problem solving skills with an emphasis on product development.\\n\\n- Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\\n\\n- Experience working with and creating data architectures.\\n\\n- Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\n\\n- Knowledge of advanced statistical techniques and concepts .\\nRoleData Analyst\\nIndustry TypeAnalytics / KPO / Research\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :MBA/PGDM in Any Specialization\\nDoctorate :Doctorate Not Required\\nKey Skills\\nData SciencePredictive ModelingNLPData ScientistArtificial IntelligenceData ManagementStatistical ModelingData ModelingMachine LearningPythonSQL',\n",
       " 'Job description\\nRoles and Responsibilities\\n\\n\\n- Selecting features, building and optimizing classifiers using machine learning techniques\\n\\n- Data mining using state-of-the-art methods\\n\\n- Enhancing data collection procedures to include information that is relevant for building analytic systems\\n\\n- Processing, cleansing, and verifying the integrity of data used for analysis\\n\\n- Doing ad-hoc analysis and presenting results in a clear manner\\n\\n- Creating automated anomaly detection systems and constant tracking of its performance\\n\\nSkills Required :\\n\\n- Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\n\\n- Experiences with one or more of the following is highly desirable: HPC/Parallelization, operationalizing ML models; cloud computing (e.g. Google Cloud, AWS, etc.); familiarity with ML frameworks such as Tensorflow, Theano, MXNet, etc\\n\\n- Good experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization\\n\\n- 2+ years of experience with computer vision and deep learning solutions, including image classification, object detection, segmentation, and equivalent computer vision-based vision tasks\\n\\n- Experience with common data science toolkits, such as R, Weka, NumPy, etc . Excellence in at least one of these is highly desirable\\n\\n- Proficiency in using query languages such as SQL, Hive, Pig\\n\\n- Good applied statistics skills, such as distributions, statistical testing, regression, etc.\\n\\n- Good scripting and programming skills\\n\\n- Data-oriented personality\\n\\n- B.Tech/M.Tech degree in from reputed institutes like IIT / NIT / BITS\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :M.Tech in Any Specialization\\nDoctorate :Doctorate Not Required\\nKey Skills\\nHiveRCloud ComputingData ScientistComputer VisionMachine LearningDeep LearningSQLPig',\n",
       " 'Job description\\nMust have min 2 to 5 years of expertise in machine learning algorithms, predictive analytics, demand forecasting in real-world projects Solid statistical background in descriptive & inferential statistics, regression, forecasting techniques\\n\\nRequired Candidate profile\\nStrong Programming background in Python (with library like Tensorflow), R, D3.js, Tableau, Spark, SQL, MongoDB\\nPrefer exposure to Optimization & Meta-heuristic algorithm & related applications\\n\\nPerks and benefits\\nFlexible Working Hours + Medical Insurance\\nRoleSoftware Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nDoctorate :Doctorate Not Required\\nKey Skills\\nMachine LearningPredictive AnalyticsPython\\nTableauDemand ForecastingDeep LearningSQLRAlgorithmsNoSQLData ScientistApplied StatisticsMongoDBSparkD3.jsTensorFlow\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description\\nThe candidate should have relevant experience in Python, R, Machine Learning, NLP, Deep Learning, CNN, KNN, Neural Network etc of 1 to 7 yrs for various role. Btech candidates 2012-2018 batch can apply for this position (Only IIT / IIM Candidates)\\nRoleTeam Lead/Technical Lead\\nIndustry TypeMiscellaneous\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nKey Skills\\npythonRIITData sciencedata scientistIIMMachine Learning',\n",
       " 'Job description\\nCouture AI Pvt Ltd, Bengaluru, India\\ninfo@couture.ai | www.couture.ai\\nJob Description: Data Scientist Openings at Couture AI\\nCouture AI Platform provides Pluggable Building Blocks to entire\\nAI stack, which are used to build and productionize varied\\nAbout Company enterprise ML and deep learning usecases. It has enabled some\\nof largest global organizations implement specific vertical\\ntargeted products build on top of its proprietary AI platform.\\nNature of Business Artificial Intelligence Platform\\nCompany Website www.couture.ai\\nJob Designation Data Scientist / Associate Data Scientist\\nJob Location Bengaluru\\nBasic Qualifications:\\n• Bachelors in Computer Science/Mathematics + Research\\n(Machine Learning, Deep Learning, Statistics, Data Mining,\\nGame Theory or core mathematical areas) from Tier-1 institutes\\n(IITs, IISc, BITS, IIITs and global ranked Univs) with good\\nacademic credentials (CGPA).\\nExperience:\\n• Building large scale AI models and/or systems.\\n• Expertise with Data, Machine Learning and Deep learning\\n(CNN, RNN, LSTM, RBM, Seq-to-Seq Autoencoders Decoders,\\netc.).\\n• Strong data structures and algorithms capabilities.\\nJob Description &\\nSkills Required\\nLooking for data science researchers.\\n• Strong working knowledge of deep learning, machine\\nlearning, and statistics.\\n- Domain understanding of Personalization, Search and\\nVisual.\\n• Strong math skills with statistical modeling and machine\\nlearning.\\n• Experience in using Python, statistical/machine learning libs.\\n• Hands-on experience building models with deep learning\\nframeworks (TensorFlow & TF tooling: TFX, TF Serving, Tensor\\nBoard, etc.).\\n• Ability to think creatively and solve problems.\\n\\n\\n\\n\\nCouture AI Pvt Ltd, Bengaluru, India\\ninfo@couture.ai | www.couture.ai\\nPreferred:\\n• Publications in highly accredited journals (If available, please\\nshare links to your published work.).\\n• Or, history of scaling ML/Deep learning algorithms at\\nmassively large scale.\\nRoleData Science\\nIndustry TypeSoftware Product\\nFunctional AreaIT Software - eCommerce, Internet Technologies\\nEmployment TypeFull Time, Permanent\\nRole CategoryNot mentioned\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nKey Skills\\nTensorflowData ScienceRnnLstmArtificial IntelligenceStatistical ModelingData MiningMachine LearningDeep LearningPython']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-3 - Web scrapping from Naukri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "\n",
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "#do click using class_name function\n",
    "\n",
    "search_btn = driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking the element for job location and salary\n",
    "\n",
    "search_loc = driver.find_element_by_xpath(\"//span[@title='Delhi / NCR'] \").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking the element for job salary\n",
    "search_sal = driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs'] \").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of jobs detail have 10 rows and 4 columns \n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Cloudstrats Technologies Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Wobot Intelligence</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Shadowfax Technologies Pvt. Ltd.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Change Magician - Machine Learning Engineer</td>\n",
       "      <td>17LIVE INC</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Operational Research</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Engineer - Big Data Engineer</td>\n",
       "      <td>CAIA -Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>HEALTH ARX TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title  \\\n",
       "0            Chaayos is Looking For Data Scientist   \n",
       "1                                   Data Scientist   \n",
       "2  Data Scientist / Data Analyst -Business Analyst   \n",
       "3                  Data Scientist Machine Learning   \n",
       "4                                    Data Engineer   \n",
       "5                                   Data Scientist   \n",
       "6      Change Magician - Machine Learning Engineer   \n",
       "7              Data Scientist Operational Research   \n",
       "8                Data Engineer - Big Data Engineer   \n",
       "9                                     Data Analyst   \n",
       "\n",
       "                                   Company  Experience  \\\n",
       "0     Chaayos (Sunshine Teahouse Pvt. Ltd.)    0-5 Yrs   \n",
       "1  Cloudstrats Technologies Private Limited    3-5 Yrs   \n",
       "2        Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "3                                 Delhivery    1-3 Yrs   \n",
       "4                        Wobot Intelligence    2-4 Yrs   \n",
       "5          Shadowfax Technologies Pvt. Ltd.    1-3 Yrs   \n",
       "6                                17LIVE INC    0-0 Yrs   \n",
       "7                                 Delhivery    1-3 Yrs   \n",
       "8  CAIA -Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "9   HEALTH ARX TECHNOLOGIES PRIVATE LIMITED    2-5 Yrs   \n",
       "\n",
       "                                           Locations  \n",
       "0                                          New Delhi  \n",
       "1                                        Delhi / NCR  \n",
       "2  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "3                                   Gurgaon/Gurugram  \n",
       "4                                        Delhi / NCR  \n",
       "5                                   Gurgaon/Gurugram  \n",
       "6  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...  \n",
       "7                                   Gurgaon/Gurugram  \n",
       "8  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...  \n",
       "9                                        Delhi / NCR  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so lets extract all the data having the job titles\n",
    "job_titles=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    job_titles.append(i.text)\n",
    "            \n",
    "#so lets extract all the data having the job location\n",
    "job_location=[]\n",
    "for i in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "    job_location.append(i.text)\n",
    "            \n",
    "#so lets extract all the data having the names\n",
    "company_name=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "    company_name.append(i.text)\n",
    "        \n",
    "# so lets extract the experience required data\n",
    "experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "experience_req=[]\n",
    "for i in experience_tags:\n",
    "    experience_req.append(i.text)\n",
    "            \n",
    "            \n",
    "    \n",
    "DS_Jobs=pd.DataFrame({})\n",
    "DS_Jobs['Title']=job_titles[:10]\n",
    "DS_Jobs['Company ']=company_name[:10]\n",
    "DS_Jobs['Experience']=experience_req[:10]\n",
    "DS_Jobs['Locations']=job_location[:10]\n",
    "    \n",
    "print(\"Shape of jobs detail have {} rows and {} columns \\n.\".format(*DS_Jobs.shape))\n",
    "DS_Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question - 4 Web Scrapping from Glassdoor.co.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "\n",
    "search_job = driver.find_element_by_id('sc.keyword')\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "#finding element for job location bar\n",
    "\n",
    "search_loc = driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n",
    "search_loc.send_keys('Noida')\n",
    "\n",
    "#do click using class_name function\n",
    "\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of glassdoor datascience jobs detail have 10 rows and 3 columns \n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Number of days ago</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taboola</td>\n",
       "      <td>5d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bechtel</td>\n",
       "      <td>15d</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lantern Digital Services</td>\n",
       "      <td>6d</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Patterns</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>21d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>12d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>13d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>11d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>United Airlines Inc.</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>12d</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Company  Number of days ago Ratings\n",
       "0                   Taboola                 5d     4.2\n",
       "1                   Bechtel                15d     3.9\n",
       "2  Lantern Digital Services                 6d     3.5\n",
       "3             Data Patterns                 1d     3.0\n",
       "4            Biz2Credit Inc                21d     3.7\n",
       "5           Priority Vendor                12d     3.7\n",
       "6                     Crowe                13d     3.8\n",
       "7                  Ericsson                11d     4.1\n",
       "8      United Airlines Inc.                 4d     4.1\n",
       "9      Gauge Data Solutions                12d     3.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so lets extract all the data having the company names\n",
    "company_name=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\"):\n",
    "    company_name.append(i.text)\n",
    "            \n",
    "#so lets extract number of days ago when job was posted\n",
    "ndays=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\"):\n",
    "    ndays.append(i.text)\n",
    "            \n",
    "\n",
    "        \n",
    "# so lets extract the ratings required data\n",
    "ratings=[]\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\"):\n",
    "    ratings.append(i.text)\n",
    "            \n",
    "            \n",
    "    \n",
    "glassdoor=pd.DataFrame({})\n",
    "glassdoor['Company ']=company_name[:10]\n",
    "glassdoor['Number of days ago']=ndays[:10]\n",
    "glassdoor['Ratings']=ratings[:10]\n",
    "    \n",
    "print(\"Shape of glassdoor datascience jobs detail have {} rows and {} columns \\n.\".format(*glassdoor.shape))\n",
    "glassdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question - 6 Scrape data of first 100 sunglasses listings on flipkart.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for Sunglasses search bar\n",
    "\n",
    "search_glasses = driver.find_element_by_class_name('_3704LK')\n",
    "search_glasses.send_keys('Sunglasses')\n",
    "\n",
    "#do click using class_name function\n",
    "\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brands=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "Discount=[]\n",
    "\n",
    "for i in urls[:3]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Brand Name of the Sunglasses\n",
    "    brands=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in brands:\n",
    "        Brands.append(i.text)\n",
    "        \n",
    "    #Product Description of the Sunglasses\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        product_desc.append(j.text)\n",
    "        \n",
    "    #Price of the Sunglasses \n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price.append(k.text)\n",
    "    \n",
    "    #Discount on the Sunglasses\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\"):\n",
    "        Discount.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sunglasses=pd.DataFrame({})\n",
    "Sunglasses['Brands ']=Brands[:100]\n",
    "Sunglasses['Product Description']=product_desc[:100]\n",
    "Sunglasses['Price']=price[:100]\n",
    "Sunglasses['Discount']=Discount[:100]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KHALEEFA</td>\n",
       "      <td>Night Vision, Polarized, UV Protection, Riding...</td>\n",
       "      <td>₹403</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EYELLUSION</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹370</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹716</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹237</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹246</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹314</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹426</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹563</td>\n",
       "      <td>29% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹298</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>HAMIW COLLECTION</td>\n",
       "      <td>UV Protection Sports Sunglasses (Free Size)</td>\n",
       "      <td>₹229</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brands                                 Product Description Price  \\\n",
       "0           KHALEEFA  Night Vision, Polarized, UV Protection, Riding...  ₹403   \n",
       "1         EYELLUSION      UV Protection Wayfarer Sunglasses (Free Size)  ₹370   \n",
       "2           Fastrack              UV Protection Aviator Sunglasses (54)  ₹716   \n",
       "3             PIRASO      UV Protection Wayfarer Sunglasses (Free Size)  ₹237   \n",
       "4       Silver Kartz  UV Protection, Gradient Rectangular Sunglasses...  ₹246   \n",
       "..               ...                                                ...   ...   \n",
       "95      Singco India              UV Protection Aviator Sunglasses (58)  ₹314   \n",
       "96    ROZZETTA CRAFT                UV Protection Round Sunglasses (53)  ₹426   \n",
       "97          Fastrack                   Mirrored Aviator Sunglasses (55)  ₹563   \n",
       "98            PIRASO   UV Protection Rectangular Sunglasses (Free Size)  ₹298   \n",
       "99  HAMIW COLLECTION        UV Protection Sports Sunglasses (Free Size)  ₹229   \n",
       "\n",
       "   Discount  \n",
       "0   68% off  \n",
       "1   83% off  \n",
       "2   20% off  \n",
       "3   85% off  \n",
       "4   83% off  \n",
       "..      ...  \n",
       "95  84% off  \n",
       "96  88% off  \n",
       "97  29% off  \n",
       "98  88% off  \n",
       "99  85% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking the element for getting the full page of Review\n",
    "\n",
    "search_rev = driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm'] \").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_pages=[]\n",
    "for i in driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a\"):\n",
    "    urls_pages.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]\n",
    "\n",
    "\n",
    "for i in urls_pages[:11]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Rating of the Phone\n",
    "    rating=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for i in rating:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    #Review Summary of the Phone\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        Review_summary.append(j.text)\n",
    "        \n",
    "    #Full Review of the Phone \n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "        Full_review.append(k.text)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone=pd.DataFrame({})\n",
    "phone['Rating ']=Rating[:100]\n",
    "phone['Review Summary']=Review_summary[:100]\n",
    "phone['Full Review']=Full_review[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>i was confused between 11 and 11 pro. i was go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Product is nice at the deviled time the delive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Does the job</td>\n",
       "      <td>phone is good but in display is 720p lcd in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Everything is perfect pictures come out so cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>I dreamt about this day from a long time.... G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating          Review Summary  \\\n",
       "0        5              Brilliant   \n",
       "1        5       Perfect product!   \n",
       "2        5          Great product   \n",
       "3        5      Worth every penny   \n",
       "4        5              Fabulous!   \n",
       "..     ...                    ...   \n",
       "95       3  Mind-blowing purchase   \n",
       "96       5              Fabulous!   \n",
       "97       5           Does the job   \n",
       "98       5              Fabulous!   \n",
       "99       5                Awesome   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  i was confused between 11 and 11 pro. i was go...  \n",
       "96  Product is nice at the deviled time the delive...  \n",
       "97  phone is good but in display is 720p lcd in th...  \n",
       "98  Everything is perfect pictures come out so cle...  \n",
       "99  I dreamt about this day from a long time.... G...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.8 - Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for Sneakers search bar\n",
    "\n",
    "search_glasses = driver.find_element_by_class_name('_3704LK')\n",
    "search_glasses.send_keys('Sneakers')\n",
    "\n",
    "#do click using class_name function\n",
    "\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brands=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "Discount=[]\n",
    "\n",
    "for i in urls[:4]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Brand Name of the Sneakers\n",
    "    brands=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in brands:\n",
    "        Brands.append(i.text)\n",
    "        \n",
    "    #Product Description of the Sneakers\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        product_desc.append(j.text)\n",
    "        \n",
    "    #Price of the Sneakers \n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price.append(k.text)\n",
    "    \n",
    "    #Discount on the Sneakers\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\"):\n",
    "        Discount.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sneakers=pd.DataFrame({})\n",
    "Sneakers['Brands ']=Brands[:100]\n",
    "Sneakers['Product Description']=product_desc[:100]\n",
    "Sneakers['Price']=price[:100]\n",
    "Sneakers['Discount']=Discount[:100]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Birde</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹252</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹424</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹748</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KULP</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>₹425</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India hub</td>\n",
       "      <td>Trendy Fashion Combo Pack of 2 Sneakers For Men</td>\n",
       "      <td>₹389</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Birde</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹319</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹1,038</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Axter</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>31% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SPADE CLUB</td>\n",
       "      <td>Combo Pack of 4 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹689</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brands                                 Product Description   Price  \\\n",
       "0        Birde                                   Sneakers For Men    ₹252   \n",
       "1       BRUTON  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...    ₹424   \n",
       "2     CALCADOS                                   Sneakers For Men    ₹748   \n",
       "3         KULP  Combo pack of 2 casual sneaker shoes for men S...    ₹425   \n",
       "4    India hub    Trendy Fashion Combo Pack of 2 Sneakers For Men    ₹389   \n",
       "..         ...                                                ...     ...   \n",
       "95       Birde                                   Sneakers For Men    ₹319   \n",
       "96       SPARX  Combo Pack of 4 Casual Sneakers With Sneakers ...  ₹1,038   \n",
       "97       Axter  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...    ₹299   \n",
       "98      BRUTON                                   Sneakers For Men    ₹299   \n",
       "99  SPADE CLUB      Combo Pack of 4 Casual Shoes Sneakers For Men    ₹689   \n",
       "\n",
       "   Discount  \n",
       "0   49% off  \n",
       "1   87% off  \n",
       "2   62% off  \n",
       "3   57% off  \n",
       "4   87% off  \n",
       "..      ...  \n",
       "95  23% off  \n",
       "96  78% off  \n",
       "97  87% off  \n",
       "98  31% off  \n",
       "99  57% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: Go to the link - https://www.myntra.com/shoes\n",
    "\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Clicking the element for getting the Price filter to \"Rs. 6649 to Rs. 13099\"\n",
    "\n",
    "search_price = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking the element for getting the color of the shoes\"Black\"\n",
    "search_color= driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='results-showMoreContainer']//a\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brands=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "\n",
    "for i in urls[:4]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Brand Name of the Shoes\n",
    "    brands=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    for i in brands:\n",
    "        Brands.append(i.text)\n",
    "        \n",
    "    #Product Description of the Shoes\n",
    "    for j in driver.find_elements_by_xpath(\"//h4[@class='product-product']\"):\n",
    "        product_desc.append(j.text)\n",
    "        \n",
    "    #Price of the Shoes \n",
    "    for k in driver.find_elements_by_xpath(\"//span[@class='product-discountedPrice']\"):\n",
    "        price.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women REACT Running Shoes</td>\n",
       "      <td>Rs. 7796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex LEBRON XVIII Basketball</td>\n",
       "      <td>Rs. 12316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex COSMIC UNITY Basketball</td>\n",
       "      <td>Rs. 11470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM FREAK 2 Basketball</td>\n",
       "      <td>Rs. 7721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men REACT MILER Running Shoes</td>\n",
       "      <td>Rs. 8246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Solid Leather Gladiators</td>\n",
       "      <td>Rs. 9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Solid Leather Ballerinas</td>\n",
       "      <td>Rs. 8799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Leather Formal Derbys</td>\n",
       "      <td>Rs. 6749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged RC Sportstyle Sneakers</td>\n",
       "      <td>Rs. 11199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>Rs. 7199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Brands              Product Description      Price\n",
       "0                   Nike       Women REACT Running Shoes   Rs. 7796\n",
       "1                   Nike  Unisex LEBRON XVIII Basketball  Rs. 12316\n",
       "2                   Nike  Unisex COSMIC UNITY Basketball  Rs. 11470\n",
       "3                   Nike     Men ZOOM FREAK 2 Basketball   Rs. 7721\n",
       "4                   Nike   Men REACT MILER Running Shoes   Rs. 8246\n",
       "..                   ...                             ...        ...\n",
       "95  Heel & Buckle London  Women Solid Leather Gladiators   Rs. 9093\n",
       "96             Cole Haan  Women Solid Leather Ballerinas   Rs. 8799\n",
       "97          Hush Puppies       Men Leather Formal Derbys   Rs. 6749\n",
       "98          UNDER ARMOUR  Charged RC Sportstyle Sneakers  Rs. 11199\n",
       "99                  FILA                  Women Sneakers   Rs. 7199\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shoes=pd.DataFrame({})\n",
    "Shoes['Brands ']=Brands[0:100]\n",
    "Shoes['Product Description']=product_desc[0:100]\n",
    "Shoes['Price']=price[0:100]\n",
    "Shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question-9 - Web Scrapping from https://www.amazon.in/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for Laptop search bar\n",
    "\n",
    "search_laptop = driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_laptop.send_keys('Laptop')\n",
    "\n",
    "#do click using id function\n",
    "\n",
    "search_btn = driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i7 filter\n",
    "\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i9 filter\n",
    "\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]   \n",
    "#Title of  Laptops\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\"):\n",
    "    Title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "Ratings=[]\n",
    "price=[]\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    #fetching the ratings of laptop\n",
    "    try:\n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']\")\n",
    "        Ratings.append(rating.text)\n",
    "    except:\n",
    "         Ratings.append('--')\n",
    "    #fetching the Price of laptop\n",
    "    try:\n",
    "        pay=driver.find_element_by_id(\"priceblock_ourprice\")\n",
    "        price.append(pay.text)\n",
    "    except:\n",
    "         price.append('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Ratings),len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nmae of the Laptop</th>\n",
       "      <th>Ratings of Laptop</th>\n",
       "      <th>Price of the Laptop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...</td>\n",
       "      <td>3.2 out of 5</td>\n",
       "      <td>₹ 83,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>₹ 97,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>₹ 54,999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo Ideapad 5 Intel i7 11th Gen 15.6\" Thin ...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>₹ 76,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>₹ 97,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>₹ 86,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "      <td>₹ 84,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>4.7 out of 5</td>\n",
       "      <td>₹ 89,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Dell G7 7500 15.6inch FHD 300 Hz Dis...</td>\n",
       "      <td>--</td>\n",
       "      <td>₹ 1,70,587.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>3.1 out of 5</td>\n",
       "      <td>₹ 26,990.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Nmae of the Laptop  Ratings of Laptop  \\\n",
       "0  Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...      3.2 out of 5   \n",
       "1  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...      4.2 out of 5   \n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i5-1...      4.4 out of 5   \n",
       "3  Lenovo Ideapad 5 Intel i7 11th Gen 15.6\" Thin ...        5 out of 5   \n",
       "4  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...      4.2 out of 5   \n",
       "5  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...      4.1 out of 5   \n",
       "6  HP Pavilion (2021) Thin & Light 11th Gen Core ...      4.5 out of 5   \n",
       "7  HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...      4.7 out of 5   \n",
       "8  (Renewed) Dell G7 7500 15.6inch FHD 300 Hz Dis...                --   \n",
       "9  Life Digital Laptop 15.6-inch (39.62 cms) (Int...      3.1 out of 5   \n",
       "\n",
       "  Price of the Laptop  \n",
       "0         ₹ 83,990.00  \n",
       "1         ₹ 97,990.00  \n",
       "2         ₹ 54,999.00  \n",
       "3         ₹ 76,990.00  \n",
       "4         ₹ 97,990.00  \n",
       "5         ₹ 86,990.00  \n",
       "6         ₹ 84,990.00  \n",
       "7         ₹ 89,990.00  \n",
       "8       ₹ 1,70,587.00  \n",
       "9         ₹ 26,990.00  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amazon_laptop=pd.DataFrame({})\n",
    "Amazon_laptop['Nmae of the Laptop ']=Title[0:10]\n",
    "Amazon_laptop['Ratings of Laptop']=Ratings[0:10]\n",
    "Amazon_laptop['Price of the Laptop']=price[0:10]\n",
    "Amazon_laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
